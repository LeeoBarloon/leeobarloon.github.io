<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"/>




  <link href="//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">



<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=0.5.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="Leeo‘s Blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=0.5.0" />






<meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="Leeo‘s Blog">
<meta property="og:url" content="http://leeobarloon.github.io/index.html">
<meta property="og:site_name" content="Leeo‘s Blog">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Leeo‘s Blog">
<meta name="twitter:description">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>

  <title> Leeo‘s Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  








  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Leeo‘s Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home fa-fw"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive fa-fw"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags fa-fw"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-user fa-fw"></i> <br />
            
            关于
          </a>
        </li>
      

      
      
      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">

    

    
    

    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/02/18/机器学习实战-学习笔记04/" itemprop="url">
                  机器学习实战-学习笔记04
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-02-18T19:45:24+08:00" content="2016-02-18">
              2016-02-18
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/02/18/机器学习实战-学习笔记04/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/02/18/机器学习实战-学习笔记04/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="u673A_u5668_u5B66_u4E60_u5B9E_u6218-_u5B66_u4E60_u7B14_u8BB004"><a href="#u673A_u5668_u5B66_u4E60_u5B9E_u6218-_u5B66_u4E60_u7B14_u8BB004" class="headerlink" title="机器学习实战-学习笔记04"></a>机器学习实战-学习笔记04</h2><p>前两次读书笔记中分别介绍了两种分类方法，下面，我们利用概率论的一些知识，来对数据进行分类</p>
<blockquote>
<p>朴素贝叶斯分类</p>
</blockquote>
<p>之所以称之为<code>朴素</code>，是因为整个过程只做最原始，最简单的假设</p>
<p>朴素贝叶斯分类的优缺点如下：</p>
<blockquote>
<p>优点: 在数据较少的情况下仍然有效，可以处理多类别问题<br>缺点: 对于输入数据的准备方式比较敏感<br>使用数据类型: 标称型数据</p>
</blockquote>
<p>其实利用概率来进行分类的原理说起来也很简单，比如：</p>
<p>如果我们有两个类别，C1和C2，那么我们来判断某个数据点（x,y)的类型到底为那个的依据就是该数据点是类型C1或者C2的概率那个更大，即：<br>    如果 $P_1(x,y)$和$P_2(x,y)$分别表示(X,Y)是C1和C2的概率<br>    那么：</p>
<pre><code>* 如果$P_1(x,y)$ &gt; $P_2(x,y)$，那么（X,Y)就属于C1
* 如果$P_2(x,y)$ &gt; $P_1(x,y)$，那么（X,Y)就属于C2
</code></pre><p>下面，我们要引入<code>条件概率</code>的概念，如果不熟悉的，可以查看一下其<a href="http://baike.baidu.com/link?url=vuSyDANLl24kp4yiklGDUcayxPCWA3HlRPzTs3EEVqoOqXlnnBGkHsHdOXXQoWom2wF-C4tivgQJr5YJR0POz_" target="_blank" rel="external">概念</a></p>
<p>上文的$P_i(x,y)$，换成条件概率的表达就是：$P(c_i|x,y)$，表示给定的（x,y)点，那么其属于$c_i$的概率是多少，根据贝叶斯公式得到：</p>
<p>$P(c_i|x,y)=\frac{P(x,y|c_i)P(c_i)}{P(x,y)}$</p>
<p>下面，我们就看一下代码如何实现：</p>
<pre><code># -*- encoding=UTF-8


def load_data_set():
    posting_list = [[&apos;my&apos;, &apos;dog&apos;, &apos;has&apos;, &apos;flea&apos;, &apos;problems&apos;, &apos;help&apos;, &apos;please&apos;],
                    [&apos;maybe&apos;, &apos;not&apos;, &apos;take&apos;, &apos;him&apos;, &apos;to&apos;, &apos;dog&apos;, &apos;park&apos;, &apos;stupid&apos;],
                    [&apos;my&apos;, &apos;dalmation&apos;, &apos;is&apos;, &apos;so&apos;, &apos;cute&apos;, &apos;I&apos;, &apos;love&apos;, &apos;him&apos;],
                    [&apos;stop&apos;, &apos;posting&apos;, &apos;stupid&apos;, &apos;worthless&apos;, &apos;garbage&apos;],
                    [&apos;mr&apos;, &apos;licks&apos;, &apos;ate&apos;, &apos;my&apos;, &apos;steak&apos;, &apos;how&apos;, &apos;to&apos;, &apos;stop&apos;, &apos;him&apos;],
                    [&apos;quit&apos;, &apos;buying&apos;, &apos;worthless&apos;, &apos;dog&apos;, &apos;food&apos;, &apos;stupid&apos;]]
    class_vec = [0, 1, 0, 1, 0, 1];
    return posting_list, class_vec


def create_vocal_list(data_set):
    &quot;&quot;&quot;
    将所有输入的字符,合并到一个set中,用于消除重复的字符,并返回一个list

    :param data_set:
    :return:
    &quot;&quot;&quot;
    vocab_set = set([])
    for document in data_set:
        vocab_set = vocab_set | set(document)
    return list(vocab_set)


def set_of_words_2_vec(vocab_list, input_set):
    &quot;&quot;&quot;
    如果vocab_list 含有 input_set中的单词,则将其所在的index设置为1

    :param vocab_list:
    :param input_set:
    :return:
    &quot;&quot;&quot;
    return_vec = [0] * len(vocab_list)
    for word in input_set:
        if word in vocab_list:
            return_vec[vocab_list.index(word)] = 1
        else:
            print &quot;the word: %s is not in my Vocabulary!&quot; % word
    return return_vec
</code></pre><p>按照上述方法，我们就可以将一组单词变成词向量了，下面我们就要利用之前提到的朴素贝叶斯算法，来获得某个单词属于哪个类型的概率是多少：</p>
<p>$P(c_i|\textbf{w})$</p>

          
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/02/16/机器学习实战-学习笔记03/" itemprop="url">
                  机器学习实战-学习笔记03
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-02-16T14:55:22+08:00" content="2016-02-16">
              2016-02-16
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/02/16/机器学习实战-学习笔记03/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/02/16/机器学习实战-学习笔记03/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="u673A_u5668_u5B66_u4E60__u8BFB_u4E66_u7B14_u8BB003"><a href="#u673A_u5668_u5B66_u4E60__u8BFB_u4E66_u7B14_u8BB003" class="headerlink" title="机器学习 读书笔记03"></a>机器学习 读书笔记03</h2><p>下面来学习一下机器学习中的另外一个常用的算法：<code>决策树</code></p>
<p>决策树，这个名字看上去很高大上，但其实程序员应该很很熟悉这个概念，看下面这个图：</p>
<p><img src="http://ceobf.img47.wal8.com/img47/536775_20160129105532/145563108783.png" alt="img_01"></p>
<p>是不是很像流程图？对，其实这就是一个简单的决策树</p>
<p>下面我们来看看决策树算法的优缺点吧：</p>
<blockquote>
<p>优点: 计算复杂度不高，输出结果易于理解，对中间值的缺失不明感，可以处理不相关的特征数据<br>缺点: 可能产生过度匹配问题<br>使用数据类型: 数值型和标称型</p>
</blockquote>
<p>决策树要解决的问题就是，按照一系列还没有分类的数据的特征，对其进行分类，那么，首先要解决的问题就是，当前数据集上哪个特征在划分数据分类的时候起到决定作用。为了找到决定性的特征，我们必须评估每个特征。</p>
<p>将数据进行分类的伪代码如下：</p>
<pre><code>createBranch()
    if so return 类标签：
    else
        寻找到划分数据集的最好特征
        划分数据集
        创建分支节点
            for 每个划分的子集
                调用函数createBranch()并增加返回结果到分支节点中
        return 分支节点
</code></pre><p>可以看到，这是一个递归函数</p>
<p>在划分数据到时候，书中采取的是ID3算法，感兴趣的可以点此进行<a href="https://zh.wikipedia.org/zh-tw/ID3%E7%AE%97%E6%B3%95" target="_blank" rel="external">查看</a></p>
<h3 id="u8BA1_u7B97_u4FE1_u606F_u589E_u76CA_u548C_u71B5"><a href="#u8BA1_u7B97_u4FE1_u606F_u589E_u76CA_u548C_u71B5" class="headerlink" title="计算信息增益和熵"></a>计算信息增益和熵</h3><p>下面我们先来看两个定义:</p>
<blockquote>
<p>信息增益（information gain) 和 熵(entropy)</p>
</blockquote>
<p>好吧，我们先不用弄明白这两个概念到底是什么，先来看两个公式吧，然后通过程序来加以了解</p>
<ol>
<li><p>如果待分类的事务可能划分在多个分类中，则符号Xi的信息期望值为：</p>
<p> <img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large l(x_i)=-log_2p(x_i)" style="border:none;"></p>
</li>
<li><p>计算熵的，我们就需要计算所有类别所有可能值包含的信息期望值：</p>
<p> <img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large H=\sum_{i=1}^{n}p(x_i)log_2p(x_i)" style="border:none;"></p>
</li>
</ol>
<p>有了公式，我们就可以写代码啦，下面这段代码就是计算数据接的香农熵的代码：</p>
<pre><code>from math import log

def calc_channon_ent(data_set):
    &quot;&quot;&quot;
    计算data_set的熵
    &quot;&quot;&quot;
    num_entries = len(data_set)
    label_counts = {}
    for feat_vec in data_set:
        current_label = feat_vec[-1]  # 最后一个数据
        if current_label not in label_counts.keys():
            label_counts[current_label] = 0
        label_counts[current_label] += 1
    shannon_ent = 0.0
    for key in label_counts:
        prob = float(label_counts[key])/num_entries # 概率计算
        shannon_ent -= prob * log(prob, 2)  # 熵计算

    return shannon_ent
</code></pre><p>根据上述公式，我们就可以获得一个数据集合的熵，可以看到，我们使用所有类标签的发生概率计算该类别的概率。然后用这个概率得到了熵。</p>
<p>测试一下，我们可以自己先创造一些测试数据：</p>
<pre><code>def create_data_set():
    data_set = [
                [1, 1, &apos;yes&apos;],
                [1, 1, &apos;yes&apos;],
                [1, 0, &apos;no&apos;],
                [0, 1, &apos;no&apos;],
                [0, 1, &apos;no&apos;]]
    labels = [&apos;no surfacing&apos;, &apos;flippers&apos;]
    return data_set, labels
</code></pre><p>然后，可以看看该集合的熵是多少了        </p>
<pre><code>if __name__ == &apos;__main__&apos;:
    data_set, labels = create_data_set()
    shannon_ent = calc_channon_ent(data_set)
    print(shannon_ent)
</code></pre><p>获得的结果是：</p>
<pre><code>&gt;&gt;0.970950594455
</code></pre><p>你可以随意修改上述测试数据，看一看熵随之变化的规律，我们会发现，如果混入的类型越高，则熵越大，在百度百科中，对熵有这样一段描述：</p>
<blockquote>
<p>熵是一个系统中”无秩序”的程度，也表征生命活动过程质量的一种度量</p>
</blockquote>
<p>我们的熵计算从某种意义上，符合该定义~</p>
<h3 id="u5212_u5206_u6570_u636E_u96C6"><a href="#u5212_u5206_u6570_u636E_u96C6" class="headerlink" title="划分数据集"></a>划分数据集</h3><p>我们学会了如何度量数据集合的无序程度，那么我们就来学习如何划分数据集。我们将对每个特征划分数据集合的结果计算一次熵，然后判断按照哪个特征划分数据是最好的划分方式~。</p>
<p>下面先来看一段代码：</p>
<pre><code>def split_data_set(data_set, axis, value):
    ret_data_set = []  # 创建新的list对象

    # 抽取符合要求的元素
    for feat_vec in data_set:
        if feat_vec[axis] == value:
            reduced_feat_vec = feat_vec[:axis]
            reduced_feat_vec.extend(feat_vec[axis+1:])
            ret_data_set.append(reduced_feat_vec)
    return ret_data_set
</code></pre><p>可以看出，该方法将index=axis的特征值为value的那些特征向量提取出来</p>
<p>接下来，我们就将<code>划分数据</code>和<code>计算熵</code>这两个算法加以结合，来找到最好的划分方法：</p>
<pre><code>def choose_best_feature_to_split(data_set):
    num_features = len(data_set[0])-1

    base_entropy = calc_channon_ent(data_set)

    best_info_gain = 0.0;
    best_feature = -1;

    for i in range(num_features):
        feat_list = [example[i] for example in data_set]
        unique_values = set(feat_list)
        new_entropy = 0.0
        for value in unique_values:
            sub_data_set = split_data_set(data_set, i, value)
            prob = len(sub_data_set)/float(len(data_set))
            new_entropy += prob * calc_channon_ent(sub_data_set)
        info_gain = base_entropy - new_entropy  # 信息增益
        if info_gain &gt; best_info_gain:
            best_info_gain = info_gain
            best_feature = i
    return best_feature
</code></pre><p>该方法可以获得最好的划分方式，使得按照该特征进行划分的信息增益最大，也就是说，这样使得信息无序度变得最小，使得划分的数据更加有序（好牛B的样子…)</p>
<p>经过测试，我们发现 index=0的特征值可以使得划分最为有序~</p>
<h3 id="u6784_u5EFA_u51B3_u7B56_u6811"><a href="#u6784_u5EFA_u51B3_u7B56_u6811" class="headerlink" title="构建决策树"></a>构建决策树</h3><p>下面还是先来看代码：</p>
<pre><code>def majority_count(class_list):
    class_count = {}
    for vote in class_list:
        if vote not in class_count.keys():
            class_count[vote] = 0
        class_count[vote] += 1
    sorted_class_count = sorted(class_count.iteritems(), key=operator.itemgetter(1), reverse=True)
    return sorted_class_count[0][0]


def create_tree(data_set, labels):
    class_list = [example[-1] for example in data_set]
    &quot;&quot;&quot;

    构建树,有两个结束条件:
    1. 程序遍历完所有划分数据的属性
    2. 每个分支下的所有实例都具有相同的分类

    &quot;&quot;&quot;

    # 判断分类是否相同
    if class_list.count(class_list[0]) == len(class_list):
        return class_list[0]

    # 判断是否遍历完所有的属性
    if len(data_set[0]) == 1:
        return majority_count(class_list)

    best_feat = choose_best_feature_to_split(data_set)
    best_feat_label = labels[best_feat]
    my_tree = {best_feat_label: {}}
    del(labels[best_feat])
    feat_values = [example[best_feat] for example in data_set]
    unique_vals = set(feat_values)
    for value in unique_vals:
        sub_Labels = labels[:]
        my_tree[best_feat_label][value] = create_tree(split_data_set(data_set, best_feat, value), sub_Labels)
    return my_tree
</code></pre><p>最终，终于得到了决策树：</p>
<pre><code>{&apos;no surfacing&apos;: {0: &apos;no&apos;, 1: {&apos;flippers&apos;: {0: &apos;no&apos;, 1: &apos;yes&apos;}}}}
</code></pre>
          
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/02/11/机器学习实战-Octave学习/" itemprop="url">
                  机器学习实战-Octave学习
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-02-11T22:39:56+08:00" content="2016-02-11">
              2016-02-11
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/02/11/机器学习实战-Octave学习/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/02/11/机器学习实战-Octave学习/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/01/30/机器学习-课程进度-第一周/" itemprop="url">
                  机器学习-课程进度-第一周
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-01-30T22:33:21+08:00" content="2016-01-30">
              2016-01-30
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/01/30/机器学习-课程进度-第一周/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/01/30/机器学习-课程进度-第一周/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="u673A_u5668_u5B66_u4E60_u8FDB_u5EA6"><a href="#u673A_u5668_u5B66_u4E60_u8FDB_u5EA6" class="headerlink" title="机器学习进度"></a>机器学习进度</h2><p>乘学习的激情还没有磨灭，报了Coursera上的机器学习的<a href="https://www.coursera.org/learn/machine-learning/home/welcome" target="_blank" rel="external">课程</a>，主讲老师还是<a href="http://baike.baidu.com/link?url=JeEwqPqM_TpBKTf80IFRpzbwCTeiYtN9xbjnzPNBlAxCeetxzrEhsjJyZX0shMHPLZy58kh7RrM-sDvVBLtPa6TnkAlPnr3RhF2glR2DsubfAM-iyrcEl0eeUbjMc2S79dZs8OK9BpYWRj_l9n94a_" target="_blank" rel="external">Andrew Ng</a>，第一周总算是学完了</p>
<p>留贴纪念一下，争取接下来的进度也能顺利</p>
<hr>
<p><img src="http://ceobf.img47.wal8.com/img47/536775_20160129105532/145416435047.png" alt="pic_1"></p>
<hr>
<p><img src="http://ceobf.img47.wal8.com/img47/536775_20160129105532/145416434955.png" alt="pic_2"></p>

          
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/01/24/Matplotlib安装和使用简要说明/" itemprop="url">
                  Matplotlib安装和使用简要说明
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-01-24T18:56:40+08:00" content="2016-01-24">
              2016-01-24
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/01/24/Matplotlib安装和使用简要说明/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/01/24/Matplotlib安装和使用简要说明/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="u7B80_u8981_u4ECB_u7ECD"><a href="#u7B80_u8981_u4ECB_u7ECD" class="headerlink" title="简要介绍"></a>简要介绍</h1><p>在Matplotlib官网上看到的介绍如下：</p>
<blockquote>
<p>matplotlib is a python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. matplotlib can be used in python scripts, the python and ipython shell (ala MATLAB®* or Mathematica®†), web application servers, and six graphical user interface toolkits</p>
</blockquote>
<p>我们可以看到用这个工具可以绘制出质量很高的图例：<br><img src="http://matplotlib.org/_static/logo_sidebar_horiz.png" alt="figure1"></p>
<h1 id="u5B89_u88C5"><a href="#u5B89_u88C5" class="headerlink" title="安装"></a>安装</h1><p>在MAC下的安装很简单：</p>
<blockquote>
<p>$ pip install matplotlib</p>
</blockquote>
<p>安装成功后，可以在matplotlib上找一些例子试试看，比如：</p>
<pre><code>import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation


def data_gen(t=0):
    cnt = 0
    while cnt &lt; 1000:
        cnt += 1
        t += 0.1
        yield t, np.sin(2*np.pi*t) * np.exp(-t/10.)


def init():
    ax.set_ylim(-1.1, 1.1)
    ax.set_xlim(0, 10)
    del xdata[:]
    del ydata[:]
    line.set_data(xdata, ydata)
    return line,

fig, ax = plt.subplots()
line, = ax.plot([], [], lw=2)
ax.grid()
xdata, ydata = [], []


def run(data):
    # update the data
    t, y = data
    xdata.append(t)
    ydata.append(y)
    xmin, xmax = ax.get_xlim()

    if t &gt;= xmax:
        ax.set_xlim(xmin, 2*xmax)
        ax.figure.canvas.draw()
    line.set_data(xdata, ydata)

    return line,

ani = animation.FuncAnimation(fig, run, data_gen, blit=False, interval=10,
                              repeat=False, init_func=init)
plt.show()
</code></pre><p>然后运行一下，就可以看到这样的图样, nice~<br><img src="http://img0.ph.126.net/TDyKUq50DtiTQEEP0vjQrA==/6631352539215188664.png" alt="figure_01"></p>
<p>另外，在官网上也可以找到大量的<a href="http://matplotlib.org/examples/index.html" target="_blank" rel="external">例子和说明文档</a></p>

          
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/01/24/机器学习实战-学习笔记02/" itemprop="url">
                  机器学习实战-学习笔记02
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-01-24T11:09:51+08:00" content="2016-01-24">
              2016-01-24
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/01/24/机器学习实战-学习笔记02/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/01/24/机器学习实战-学习笔记02/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="u673A_u5668_u5B66_u4E60__u8BFB_u4E66_u7B14_u8BB002"><a href="#u673A_u5668_u5B66_u4E60__u8BFB_u4E66_u7B14_u8BB002" class="headerlink" title="机器学习 读书笔记02"></a>机器学习 读书笔记02</h2><p>我们一起来学习机器学习中的第一个算法：</p>
<h3 id="k-_u8FD1_u90BB_u7B97_u6CD5_28k-Nearest_Neighbour_u7B97_u6CD5_uFF0CKNN_u7B97_u6CD5_uFF09"><a href="#k-_u8FD1_u90BB_u7B97_u6CD5_28k-Nearest_Neighbour_u7B97_u6CD5_uFF0CKNN_u7B97_u6CD5_uFF09" class="headerlink" title="k-近邻算法(k-Nearest Neighbour算法，KNN算法）"></a>k-近邻算法(k-Nearest Neighbour算法，KNN算法）</h3><p>什么是k-近邻算法呢？<br>书中的定义比较简单：</p>
<blockquote>
<p>采用测量不同特征值之间的距离方法进行分类的算法</p>
</blockquote>
<p>而百度百科上的解释更全面一点</p>
<blockquote>
<p>K最近邻(k-Nearest Neighbour，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。</p>
<p>用官方的话来说，所谓K近邻算法，即是给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的K个实例（也就是上面所说的K个邻居）， 这K个实例的多数属于某个类，就把该输入实例分类到这个类中。</p>
</blockquote>
<p>KNN算法的优点和缺点也比较明显：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>算法优点</td>
<td>精度高，对异常值不明感，无数据输入假定</td>
<td></td>
</tr>
<tr>
<td>缺点</td>
<td>计算复杂度高、空间复杂度高</td>
<td></td>
</tr>
<tr>
<td>使用数据范围</td>
<td>数值型和标称型</td>
<td></td>
</tr>
</tbody>
</table>
<hr>
<h3 id="KNN_u7B97_u6CD5_u7684_u4F2A_u4EE3_u7801_uFF1A"><a href="#KNN_u7B97_u6CD5_u7684_u4F2A_u4EE3_u7801_uFF1A" class="headerlink" title="KNN算法的伪代码："></a>KNN算法的伪代码：</h3><ol>
<li>计算已知类别数据节中的点与当前点之间的距离</li>
<li>按照距离递增顺序排序</li>
<li>选取与当前点距离最小的k个点</li>
<li>确定前k个点所在类别的出现频率</li>
<li>返回前k个点出现频率最高的类别最为当前点的预测分类</li>
</ol>
<hr>
<h3 id="kNN_u7B97_u6CD5_u7684python_u4EE3_u7801_uFF1A"><a href="#kNN_u7B97_u6CD5_u7684python_u4EE3_u7801_uFF1A" class="headerlink" title="kNN算法的python代码："></a>kNN算法的python代码：</h3><pre><code>from numpy import *
import operator

&apos;&apos;&apos;
获得已有的数据集和标签
&apos;&apos;&apos;
def createDataSet():
    group = array([[1.0, 1.1], [1.0, 1.0], [0, 0], [0, 0.1]])
    labels = [&apos;A&apos;, &apos;A&apos;, &apos;B&apos;, &apos;B&apos;]
    return group, labels

&apos;&apos;&apos;
分类算法0，获得输入的inX最应该属于的标签类型
&apos;&apos;&apos;
def classify0(inX, dataSet, labels, k):
    #计算距离
    dataSetSize = dataSet.shape[0]
    diffMat = tile(inX, (dataSetSize,1)) - dataSet
    sqDiffMat = diffMat**2
    sqDistances = sqDiffMat.sum(axis=1)
    distances = sqDistances**0.5
    sortedDistIndicies = distances.argsort()

    classCount = {}
    #选择距离最小的k个点
    for i in range(k):
        voteIlabel = labels[sortedDistIndicies[i]]
        classCount[voteIlabel] = classCount.get(voteIlabel,0)+1
    #排序    
    sortedDistIndicies = sorted(classCount.iteritems(),
                                key=operator.itemgetter(1), reverse=True)
    return sortedDistIndicies[0][0]

if __name__ == &apos;__main__&apos;:
    group, labels = createDataSet()
    label = classify0([0,0], group, labels, 3)
    print label
</code></pre><p>获得的结果是：</p>
<pre><code>$ B
</code></pre><p>在上述的代码中，会涉及到一些有关python中numpy类库的使用，请不熟悉的朋友查看相关代码或文档，当然，debug来单步调试上述代码，也是一个很好的方法，其实就是利用了欧氏距离来算了两个向量点之间的距离，然后选取了其中最短的一个，并获得了其对应的类型。</p>
<p>说明输入的测试数据[0,0]更应该属于B类数据</p>
<p>上面是我们写的第一个分类算法，但我们要知道，分类器并不一定总是正确的，我们可以通过多种方法检测分类算法的正确性。<br>我们可以通过大量的测试，来计算出分类算法的错误率，错误率是评估分类器是否有效的方法之一;</p>
<h3 id="u7B2C_u4E8C_u4E2A_u4F8B_u5B50_uFF0C_u7EA6_u4F1A_u6570_u636E_u5206_u7C7B"><a href="#u7B2C_u4E8C_u4E2A_u4F8B_u5B50_uFF0C_u7EA6_u4F1A_u6570_u636E_u5206_u7C7B" class="headerlink" title="第二个例子，约会数据分类"></a>第二个例子，约会数据分类</h3><p>在开始学习书中提到的第二个例子前，我们先要了解一下它中间要用到的一个工具：<br><a href="http://www.labri.fr/perso/nrougier/teaching/matplotlib/" target="_blank" rel="external">matplotlib</a></p>
<p>其安装和使用的简要说明请参见此<a href="http://leeobarloon.github.io/2016/01/24/Matplotlib%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8%E7%AE%80%E8%A6%81%E8%AF%B4%E6%98%8E/">文章</a></p>
<p>另外，这个例子中会用到一个样本文件，朋友们可以从这里<a href="http://download.csdn.net/detail/mctyro/6504521" target="_blank" rel="external">下载</a>,如果找不到，自行google或者baidu吧~</p>
<p>我们可以打开ch02中的<code>datingTestSet.txt</code>文档，可以发现类似这样的数据；</p>
<pre><code>40920    8.326976    0.953952    largeDoses
14488    7.153469    1.673904    smallDoses
26052    1.441871    0.805124    didntLike
75136    13.147394    0.428964    didntLike
38344    1.669788    0.134296    didntLike
72993    10.141740    1.032955    didntLike
35948    6.830792    1.213192    largeDoses
42666    13.276369    0.543880    largeDoses
67497    8.631577    0.749278    didntLike
...
</code></pre><p>神马意思呢？</p>
<p>颤抖吧，据说这是某个约会达人专门为她（注意，是她！）自己约会的对象所整理出来的一个数据样本，其中对应的特征分别是：</p>
<pre><code>* 每年获得的飞行常客里程数
* 玩视频游戏所耗时间百分比
* 每周消费的冰激凌公升数（什么鬼...)
</code></pre><p>最后一行的含义则表示该样本所属的类型：</p>
<pre><code>不喜欢的人（didntLike），
魅力一般的人（smallDoses），
极具魅力的人（largeDoses）
</code></pre><p>那么，有了这个样本类型后，该女子在下一次遇到一个新的约会对象的时候，就会通过一个算法，来预测该名男子是不是一个有魅力的人…当然，她问的问题可能会让此男摸不着头脑:”哎，你这一年飞行了多少公里啊？”,”一周你吃几次冰激凌，什么包装的？”以及”你玩不玩游戏，玩多久”之类的问题，如果遇到问这种问题的女人，请自行退散…！</p>
<p>…言归正传(写这本书的作者脑洞挺大）</p>
<p>我们看这个程序是怎嘛写滴：</p>
<pre><code>def file2matrix(filename):
fr = open(filename)
arrayOfLines = fr.readlines()
numberOfLines = len(arrayOfLines)
returnMat = zeros((numberOfLines, 3))
classLabelVector = []
index = 0
for line in arrayOfLines:
    line = line.strip()
    listFromLine = line.split(&apos;\t&apos;)
    returnMat[index, :] = listFromLine[0:3]
    classLabelVector.append(int(listFromLine[-1]))
    index+=1
return returnMat, classLabelVector

if __name__ == &apos;__main__&apos;:
    returnMat, classLabelVector = file2matrix(&apos;datingTestSet2.txt&apos;);
</code></pre><p>程序很简单，其实就是将文件中的内容，格式化的导入到内存的结构化数据中，其中zeros((x,y))的含义就是构造一个x行，y列的矩阵，每个向量用0.0填充，当然，在python中，是用二维数组表示的，比如：</p>
<pre><code>&gt;&gt;&gt; zeros((4,3))
array([[ 0.,  0.,  0.],
       [ 0.,  0.,  0.],
       [ 0.,  0.,  0.],
       [ 0.,  0.,  0.]])    
</code></pre><p>那么，接下来，我们获得了一个1000行，3列的数据结构，然后也有了这1000行数据分别代表是否是理想的约会对象的标示，接下来的任务就是利用matplotlib来绘制图像了<br>运行下面的代码：</p>
<pre><code>def draw_figure01():
    returnMat, classLabelVector = file2matrix(&apos;datingTestSet2.txt&apos;);
    fig = plt.figure()
    ax = fig.add_subplot(111)

    # 绘制返回结果中的第1和第2列数据,分别代表:玩游戏时间和冰激凌公升数
    ax.scatter(returnMat[:, 1], returnMat[:, 2])
    plt.show()


if __name__ == &apos;__main__&apos;:
    &apos;&apos;&apos;
    group, labels = createDataSet()
    label = classify0([0,0], group, labels, 3)
    print label

    &apos;&apos;&apos;
    draw_figure01()
</code></pre><p>获得的效果如下图：        </p>
<p><img src="http://img2.ph.126.net/37xd9_uaFcEVkvJ1RWN1fA==/6631419609424482845.jpg" alt="figure_02"></p>
<p>为了将两种类型的数据分清楚，可以在绘制的函数中加入尺寸和颜色的信息：</p>
<pre><code>...
ax.scatter(returnMat[:, 1], returnMat[:, 2],
    15*array(classLabelVector),15*array(classLabelVector))
...
</code></pre><p>可以看到这样的效果了：<br><img src="http://ceobf.img47.wal8.com/img47/536775_20160129105532/145403797675.png" alt="figure_03"></p>
<p>恩，感觉效果还可以…</p>
<p>但是为了计算样本之间的相差程度，我们还需要进一步的计算，如下表：</p>
<pre><code>40920    8.326976    0.953952    largeDoses
14488    7.153469    1.673904    smallDoses
26052    1.441871    0.805124    didntLike
75136    13.147394 0.428964    didntLike
</code></pre><p>我们发现，如果按照欧几里得计算公式，来计算样本之间的距离，则第一列的影响因子过大（权重过大），那么我们就需要平衡几个因素之间的影响效果，最简单的办法就是：<code>数值归一化</code>，简单点说，就是让这些熟知的特征化数值都转化到0到1之间。</p>
<pre><code>def autoNorm(dataSet):
    minValues = dataSet.min(0)
    maxValues = dataSet.max(0)
    ranges = maxValues - minValues
    normDataSet = zeros(shape(dataSet))
    m = dataSet.shape[0]
    normDataSet = dataSet - tile(minValues, (m, 1))
    normDataSet = normDataSet/tile(ranges,(m,1))
    return normDataSet, ranges, minValues
</code></pre><p>上面的代码，就是将原有矩阵中的每一个向量归一化到0到1之间的区间中了:</p>
<p>接下来，我们就可以测试一下，通过我们的kNN算法，是否可以比较准确的判断此人是否适合约会了，那么如何获得测试数据呢？其实很简单，就是从样本数据中，抽取出一部分(比如10%）作为测试数据，然后比对一下，按照算法获得的结果，是否和真实的结果一致，这样，就可以获得一个算法的正确率，代码如下:</p>
<pre><code>def datingClassTest():
    hoRadio = 0.1
    datingDataMat, datingLabels = file2matrix(&apos;datingTestSet2.txt&apos;)
    normDataSet, ranges, minValues = autoNorm(datingDataMat)
    m = normDataSet.shape[0] #获得行数
    numTestVecs = int(m*hoRadio)
    errorCount = 0
    for i in range(numTestVecs):
       classifierResult = classify0(normDataSet[i,:],normDataSet[numTestVecs:m,:], datingLabels[numTestVecs:m],3)
       print &quot;the classifier came back with: %d, the real answer is %d&quot; %(classifierResult, datingLabels[i])
       if(classifierResult!=datingLabels[i]):
           errorCount += 1.0
    print &quot;The total error rate is : %f&quot; %(errorCount/float(numTestVecs))
</code></pre><p>最后获得的错误率是5%，还是不错的（书中计算出来是2.4%,不知道是不是数据不同导致的）</p>
<p>恩，接下来，你就可以仿照这个kNN算法来写一个自己的约会对象筛查程序了</p>
<p>。。。。</p>
<p>当然是做梦啦，谁会来和程序员约会…？</p>
<p>当然，这个例子中的向量维度是很少的，总共才有3列，像书中提到的自体识别的例子，一个例子的样本最终会被转化为1024维度的矩阵，并且要和样本数据中的超多2000个向量进行距离运算，这个算法的效率是不大高的，那么接下来，我们就来看一看，为了解决这个算法效率的问题，将要引进的 <code>k决策树</code> 算法！</p>
<p>下回一起来学习…</p>

          
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/01/23/IOS Development/" itemprop="url">
                  github上的ios代码
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-01-23T23:08:13+08:00" content="2016-01-23">
              2016-01-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/IOS代码库/" itemprop="url" rel="index">
                    <span itemprop="name">IOS代码库</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/01/23/IOS Development/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/01/23/IOS Development/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>现在的IOS开发，有很多可以借鉴的轮子，我们不用再像之前一样，自己还需要写很多比较高级一些的控件，目前在很多的社区，已经有大量的高级控件以及可以借鉴的代码；对于产品初期，快速搭建一个demo效果的APP应用来说，最好的方法就是从其中挑选比较适合你么产品的开源代码，加以借鉴和使用<br>
          <div class="post-more-link text-center">
            <a class="btn" href="/2016/01/23/IOS Development/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/01/23/机器学习实战-学习笔记01/" itemprop="url">
                  机器学习实战-学习笔记01
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-01-23T21:54:01+08:00" content="2016-01-23">
              2016-01-23
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/01/23/机器学习实战-学习笔记01/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/01/23/机器学习实战-学习笔记01/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>##机器学习 读书笔记01<br>最近开始研究机器学习(Computer Learning）,发现其实已经有很多很好的资源了，其中比较著名的就是网易云课堂上的<a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学公开课 ：机器学习课程</a>，公开课的老师是一个华人，最后一查，发现他是一个大牛，哦不，是巨牛，请看他的相关介绍：<a href="http://baike.baidu.com/link?url=82UgpsKu2N8pN-9XWsJLQkeGVArb5GRdDthrAjGfwtuHEXNhWcTA7PQI9eZGGmxz9sogbViWV0annPGr0XGOMrF7Via3PdjXliQo0_umzuz6Q9EWE-g6y5NN1L_gdX1zlpV17EsqVchsQ9AlPw61w_" target="_blank" rel="external">Andrew Ng</a>，后来发现他是著名的公开课网站<a href="https://www.coursera.org/" target="_blank" rel="external">Course</a>的co-fonder，然后在这个网站上也发现了有关机器学习的课程<a href="https://www.coursera.org/learn/machine-learning/" target="_blank" rel="external">公开课</a></p>
<p>网上有学习过他的课程的网友说，网易云课堂上的课程比较老了，还是Coursera上的比较新，所以我就抱着试一试看的态度，报了他的公开课，刚好过两天就要开一期了，但愿我可以按时完成。</p>
<p>首先来看一下有关机器学习的一些概念，我在另外一篇blog里头已经整理过了，请刚兴趣的同学移步<a href="http://leeobarloon.github.io/2016/01/23/ComputerLearningConcept/">此处</a></p>
<p>后来，回家本来想翻看一下之前大学时候数学相关的书籍，然后竟然被我找到了这本书<a href="http://book.douban.com/subject/24703171/" target="_blank" rel="external">《机器学习实战》</a>，原来我去年就买过这本书，但后来发现看不大懂，看来上帝早有安排啊，哈哈~</p>
<hr>
<p>言归正传，下面我们就开始学习这本书吧~</p>
<p>在书的第一章，作者提到了机器学习常常会提到的两个概念，或者说是种类：</p>
<pre><code>1. 监督学习
2. 非监督学习
</code></pre><p>所谓监督学习，大概的意思就是这类算法知道预测什么，即目标变量的分类信息；<br>而非监督学习，则表示数据没有分类信息，也没有目标值，需要机器通过学习自己去聚合整理出有规律的信息；</p>
<p>这张表会比较好的表达出上述两种机器学习所涉及到的算法</p>
<table>
<thead>
<tr>
<th>监督学习的用途</th>
</tr>
</thead>
<tbody>
<tr>
<td>k-近邻算法</td>
<td></td>
</tr>
<tr>
<td>线性回归</td>
<td></td>
</tr>
<tr>
<td>朴素贝叶斯算法</td>
<td></td>
</tr>
<tr>
<td>局部加权线性回归</td>
<td></td>
</tr>
<tr>
<td>支持向量机</td>
<td></td>
</tr>
<tr>
<td>Ridge回归</td>
<td></td>
</tr>
<tr>
<td>决策树</td>
<td></td>
</tr>
<tr>
<td>Lasso最小回归系数估计</td>
<td></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>非监督学习的用途</th>
</tr>
</thead>
<tbody>
<tr>
<td>k-均值</td>
<td></td>
</tr>
<tr>
<td>最大期望算法</td>
<td></td>
</tr>
<tr>
<td>KBSCAN</td>
<td></td>
</tr>
<tr>
<td>Parzen窗设计</td>
<td></td>
</tr>
</tbody>
</table>
<p>如果看不懂，不要着急，因为我也看不懂 😢</p>
<h2 id="u5982_u4F55_u9009_u62E9_u7B97_u6CD5"><a href="#u5982_u4F55_u9009_u62E9_u7B97_u6CD5" class="headerlink" title="如何选择算法"></a>如何选择算法</h2><p>那么，面对所要解决的问题，我们如何选择合适的算法呢？</p>
<p>首先，我么要考虑算法的目的，然后根据目的选择对应的算法，下图只能说是一个大概，具体的策略还需要进一步学习</p>
<p><img src="http://img2.ph.126.net/nT1jFeB01R7PJiGoD4BFrg==/6631445997703530932.jpg" alt="flow-image"></p>
<p>其次，我们要考虑数据，对数据了解的越充分，越容易做出正确的算法决策，主要考虑下面几个方面；</p>
<ol>
<li>特征值是离散型变量还是连续型变量</li>
<li>特征值中是否有缺失的值</li>
<li>何种原因造成缺失</li>
<li>数据中是否存在异常值</li>
<li>某个值发生的频率如何</li>
<li>…</li>
</ol>
<h2 id="u673A_u5668_u5B66_u4E60_u5F00_u53D1_u6B65_u9AA4"><a href="#u673A_u5668_u5B66_u4E60_u5F00_u53D1_u6B65_u9AA4" class="headerlink" title="机器学习开发步骤"></a>机器学习开发步骤</h2><p>同其他的开发步骤差不多，机器学习也有如下几个步骤：</p>
<ol>
<li>收集数据</li>
<li>准备输入数据</li>
<li>分析输入数据</li>
<li>训练算法</li>
<li>测试算法</li>
<li>使用算法</li>
</ol>
<p>其中，第4和第5步骤，是机器学习的核心</p>
<p>本书主要用到的语言是<code>python</code>，并且会频繁的用到<code>python</code>中的<code>Numpy</code>类库</p>
<p>具体如何使用，请大家自行查考资料，这里就不在啰嗦了.</p>

          
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/01/23/ComputerLearningConcept/" itemprop="url">
                  Computer Learning Concept
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-01-23T16:56:02+08:00" content="2016-01-23">
              2016-01-23
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/01/23/ComputerLearningConcept/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/01/23/ComputerLearningConcept/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="u673A_u5668_u5B66_u4E60"><a href="#u673A_u5668_u5B66_u4E60" class="headerlink" title="机器学习"></a>机器学习</h1><p>机器学习的概念：<br>关于机器学习的概念有很多，我们可以从下面基本书中的定义中自己领会</p>
<h2 id="Tom_Mitchell_u2018s_Machine_Learning"><a href="#Tom_Mitchell_u2018s_Machine_Learning" class="headerlink" title="Tom Mitchell‘s Machine Learning"></a>Tom Mitchell‘s Machine Learning</h2><p>Tom Mitchell在他的《<a href="http://www.amazon.com/dp/0070428077?tag=job0ae-20" target="_blank" rel="external">Machine Learning</a>》（中文版<a href="http://www.amazon.cn/gp/product/B002WC7NH2/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;camp=536&amp;creative=3200&amp;creativeASIN=B002WC7NH2&amp;linkCode=as2&amp;tag=vastwork-23" target="_blank" rel="external">机器学习</a>)中如此定义：</p>
<blockquote>
<p>The field of machine learning is concerned with the question of how to construct computer programs that automatically improve with experience.</p>
</blockquote>
<p>Tom Mitchell还有一个更加常被别人提到的定义：</p>
<blockquote>
<p>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E</p>
</blockquote>
<p>这个概念比较绕口，翻译成中文就是：</p>
<blockquote>
<p>所谓机器学习，就是给定一个任务T和一个测量方法P，可以获得的经验E，如果针对该任务T，其针对P的测量结果性能可以得到提升，则说明其得到了学习</p>
</blockquote>
<p>##Elements of Statistical Learning<br>在《<a href="http://www.amazon.com/dp/0387848576?tag=inspiredalgor-20" target="_blank" rel="external">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</a>》中如此定义：</p>
<blockquote>
<p>Vast amounts of data are being generated in many fields, and the statisticians’s job is to make sense of it all: to extract important patterns and trends, and to understand “what the data says”. We call this learning from data.</p>
</blockquote>
<p>翻译成中文:</p>
<blockquote>
<p>在很多领域都会产生海量的数据，统计学家的工作就是让这些数据产生意义（或者说从中提取出有意义的含义）：提取重要的模式与趋势，然后弄明白“这些数据到底在说什么”.我们称之为：learning from data</p>
</blockquote>
<h2 id="Pattern_Recognition"><a href="#Pattern_Recognition" class="headerlink" title="Pattern Recognition"></a>Pattern Recognition</h2><p>Bishop在他的书《<a href="http://www.amazon.com/dp/0387310738?tag=inspiredalgor-20" target="_blank" rel="external">Pattern Recognition and Machine Learning</a>》的定义：</p>
<blockquote>
<p>One of the most interesting features of machine learning is that it lies on the boundary of several different academic disciplines, principally computer science, statistics, mathematics, and engineering. …machine learning is usually studied as part of artificial intelligence, which puts it firmly into computer science …understanding why these algorithms work requires a certain amount of statistical and mathematical sophistication that is often missing from computer science undergraduates.</p>
</blockquote>
<p>这么长的英文，不翻译成中文对不起观众…</p>
<blockquote>
<p>机器学习最有趣的地方就是：它基于几种不同学科，主要包括：计算机科学，统计学，数学，工程学等等，机器学习常用在人工智能领域（这也应该包括在计算机科学中）。要弄明白这些问题，常常需要一些统计学和数学的理论，而这些恰恰是那些从计算机科学专业别也得学生所常常遗忘掉的…</p>
</blockquote>

          
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/01/22/CreateHexo/" itemprop="url">
                  CreateHexo
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-01-22T11:18:01+08:00" content="2016-01-22">
              2016-01-22
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/01/22/CreateHexo/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/01/22/CreateHexo/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="HEXO__u521B_u5EFABlog"><a href="#HEXO__u521B_u5EFABlog" class="headerlink" title="HEXO 创建Blog"></a>HEXO 创建Blog</h1><p>决定又重新开始写blog，以前用jekyll，但这次想换成hexo，它是基于node.js的blog模板框架</p>
<p>##HEXO介绍<br><a href="https://hexo.io/zh-cn/" target="_blank" rel="external">hexo</a>是一个目前比较流行的博客框架<br>主要有如下几个优点：</p>
<ul>
<li>生成快速</li>
<li>支持 Markdown</li>
<li>一键部署</li>
<li>插件丰富</li>
</ul>
<p>##安装前提<br>安装HEXO前，必须保证您的机器上已经有：<br><a href="http://git-scm.com/" target="_blank" rel="external">git</a><br><a href="https://nodejs.org/en/" target="_blank" rel="external">node.js</a></p>
<h2 id="u5B89_u88C5Hexo_u4E0E_u5EFA_u7AD9"><a href="#u5B89_u88C5Hexo_u4E0E_u5EFA_u7AD9" class="headerlink" title="安装Hexo与建站"></a>安装Hexo与建站</h2><h3 id="install"><a href="#install" class="headerlink" title="install"></a>install</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install -g hexo-cli</span><br></pre></td></tr></table></figure>
<h3 id="setup"><a href="#setup" class="headerlink" title="setup"></a>setup</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo init &#60;fold&#62;&#10;$ cd &#60;fold&#62;&#10;$ npm install</span><br></pre></td></tr></table></figure>
<h3 id="start"><a href="#start" class="headerlink" title="start"></a>start</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server&#10;or&#10;$ hexo s</span><br></pre></td></tr></table></figure>
<p>就可以看到如下结果:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO  Hexo is running at http://0.0.0.0:4000/. Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure>
<p>说明启动成功</p>

          
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    

  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="https://avatars0.githubusercontent.com/u/16793574?v=3&s=460"
               alt="LeeoBarloon" />
          <p class="site-author-name" itemprop="name">LeeoBarloon</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">29</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            
              <span class="site-state-item-count">9</span>
              <span class="site-state-item-name">分类</span>
              
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">17</span>
              <span class="site-state-item-name">标签</span>
              </a>
          </div>

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="icon-next-heart fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LeeoBarloon</span>
</div>

<!--div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div-->



      </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  


  



  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=0.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=0.5.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=0.5.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"leeobarloon"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
  





  
  

  
  


</body>
</html>
